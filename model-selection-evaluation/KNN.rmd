---
title: "R Notebook"
output: html_notebook
---


```{r}
library(kknn)

df <- readRDS(file = "datasets/model_df.rds")
df_only_significant <- readRDS(file = "datasets/df_training_only_significant.rds")
df_no_sentiment <- readRDS(file = "datasets/df_training_no_sentiment.rds")

# here we need to make manual cv, while mantaining the imbalance
set.seed(0)

scam_df <- df[df$y == "scam",]
non_scam_df <- df[df$y != "scam",]

# 80/20
train_id_s <- sample(seq_len(nrow(scam_df)), as.integer(nrow(scam_df) * 0.8))
train_id_ns <- sample(seq_len(nrow(non_scam_df)), as.integer(nrow(non_scam_df) * 0.8))

train_df <- rbind(scam_df[train_id_s,], non_scam_df[train_id_ns,])
val_df <- rbind(scam_df[-train_id_s,], non_scam_df[-train_id_ns,])


accsTR <- NULL
accsTS <- NULL
```


```{r}

# try for k from 1 to 100
ks <- 1:100

for (k in ks) {
  # knn specifics
  knn_spec <- nearest_neighbor(neighbors = k) %>%
    set_mode("classification") %>%
    set_engine("kknn")
  # fit
  knn_fit <- knn_spec %>%
    fit(y ~ ., data = df)
  # test accuracy on training
  accsTR <- c(accsTR, (augment(knn_fit, new_data = train_df) %>%
    accuracy(truth = y, estimate = .pred_class))$.estimate)
  # test accuracy on validation
  accsTS <- c(accsTS, (augment(knn_fit, new_data = val_df) %>%
    accuracy(truth = y, estimate = .pred_class))$.estimate)
}
```

# Visualization

```{r}
ggplot(data.frame(k = ks, train = accsTR, val = accsTS), aes(x = ks, y = accsTR)) +
    ylim(0, 1) +
  labs(title = "Accuracies for  knn", x = "K", y = "Accuracy") +
    geom_line(aes(x = ks, y = accsTR, colour = "Training")) +
  geom_line(aes(x = ks, y = accsTS, colour = "Validation"))
```


```{r}
ggplot(data.frame(k = ks, train = accsTR, val = accsTS), aes(x = ks, y = accsTR)) +
    ylim(0, 1) + xlim(1,10) +
  labs(title = "Zoomed accuracies for  knn", x = "K", y = "Accuracy") +
    geom_line(aes(x = ks, y = accsTR, colour = "Training")) +
  geom_line(aes(x = ks, y = accsTS, colour = "Validation"))
```
Ks 1 to 3 seems to be the best ones, but smells overfitting to me
```{r}
knn_spec <- nearest_neighbor(neighbors = 5) %>%
    set_mode("classification") %>%
    set_engine("kknn")
  # fit
model_knn <- knn_spec %>%
    fit(y ~ ., data = df)
saveRDS(model_knn, file = "model-selection-evaluation/KNN.rds")
```


# Only significant

```{r}
scam_df <- df_only_significant[df_only_significant$y == "scam",]
non_scam_df <- df_only_significant[df_only_significant$y != "scam",]
train_df <- rbind(scam_df[train_id_s,], non_scam_df[train_id_ns,])
val_df <- rbind(scam_df[-train_id_s,], non_scam_df[-train_id_ns,])

accsTR <- NULL
accsTS <- NULL

for (k in ks) {
  # knn specifics
  knn_spec <- nearest_neighbor(neighbors = k) %>%
    set_mode("classification") %>%
    set_engine("kknn")
  # fit
  knn_fit <- knn_spec %>%
    fit(y ~ ., data = df_only_significant)
  # test accuracy on training
  accsTR <- c(accsTR, (augment(knn_fit, new_data = train_df) %>%
    accuracy(truth = y, estimate = .pred_class))$.estimate)
  # test accuracy on validation
  accsTS <- c(accsTS, (augment(knn_fit, new_data = val_df) %>%
    accuracy(truth = y, estimate = .pred_class))$.estimate)
}

ggplot(data.frame(k = ks, train = accsTR, val = accsTS), aes(x = ks, y = accsTR)) +
    ylim(0, 1) +
  labs(title = "Accuracies for  knn", x = "K", y = "Accuracy") +
    geom_line(aes(x = ks, y = accsTR, colour = "Training")) +
  geom_line(aes(x = ks, y = accsTS, colour = "Validation"))
```

```{r}
knn_spec <- nearest_neighbor(neighbors = 5) %>%
    set_mode("classification") %>%
    set_engine("kknn")
  # fit
model_knn <- knn_spec %>%
    fit(y ~ ., data = df_only_significant)
saveRDS(model_knn, file = "model-selection-evaluation/KNN_only_significant.rds")
```



# No sentiment
```{r}
scam_df <- df_no_sentiment[df_no_sentiment$y == "scam",]
non_scam_df <- df_no_sentiment[df_no_sentiment$y != "scam",]
train_df <- rbind(scam_df[train_id_s,], non_scam_df[train_id_ns,])
val_df <- rbind(scam_df[-train_id_s,], non_scam_df[-train_id_ns,])

accsTR <- NULL
accsTS <- NULL

for (k in ks) {
  # knn specifics
  knn_spec <- nearest_neighbor(neighbors = k) %>%
    set_mode("classification") %>%
    set_engine("kknn")
  # fit
  knn_fit <- knn_spec %>%
    fit(y ~ ., data = df_no_sentiment)
  # test accuracy on training
  accsTR <- c(accsTR, (augment(knn_fit, new_data = train_df) %>%
    accuracy(truth = y, estimate = .pred_class))$.estimate)
  # test accuracy on validation
  accsTS <- c(accsTS, (augment(knn_fit, new_data = val_df) %>%
    accuracy(truth = y, estimate = .pred_class))$.estimate)
}

ggplot(data.frame(k = ks, train = accsTR, val = accsTS), aes(x = ks, y = accsTR)) +
    ylim(0, 1) +
  labs(title = "Accuracies for  knn", x = "K", y = "Accuracy") +
    geom_line(aes(x = ks, y = accsTR, colour = "Training")) +
  geom_line(aes(x = ks, y = accsTS, colour = "Validation"))
```
```{r}
knn_spec <- nearest_neighbor(neighbors = 5) %>%
    set_mode("classification") %>%
    set_engine("kknn")
  # fit
model_knn <- knn_spec %>%
    fit(y ~ ., data = df_no_sentiment)
saveRDS(model_knn, file = "model-selection-evaluation/KNN_no_sentiment.rds")
```
